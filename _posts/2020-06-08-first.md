---
title : "Distributed File Systems"
excerpt : "테스트"
categories :	
 - Data Mining
tags :
 - Blog
---

Github page 테스트

마크다운 

타이틀 {{page.title}}



$x = \dot{a} + \frac{2}{5}$











알고리눈 cpu\에서 작동하고

메모리에 접근한다. 

알고리즘은 메머리의



데이터가 큰경우 메모리에 다 들어 가지 못한다.

그래서 disk 에 있는 데이터를 저장하여 접근하면 서 수행하였다. (기존의 DM)

그러나 이보다 더 큰 경우 어떻게 처리할까

구글의 검색 엔진은 

10bllion 의 웹페이지를 처리해야하고 하나당 20키로여도 

200 테라바이트를 처리해야한다. 

디스크를 읽는데 50m/s 가 걸린다 치면

read 에 46일이 소모된다



데이터를 chunk로 나누고 

cpu를 병렬로 연결하여 작업을 수행한다면 

시간을 줄일 수 있다. 