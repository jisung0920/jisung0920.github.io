# Frequent Itemsets

데이터를 특징짓기위한 기술의 주요 종류 중 하나를 다룹니다. : the discovery of Frequent Itemsets.

이 문제는 종종 'association rule' 찾기로 보여집니다. 비록 나중에는 데이터의 더 복잡합 특징을 다루지만, 이 찾기는 기본적으로 Frequent Itemsets 찾기에 기반한 찾기 입니다.

우리는 데이터의 '마켓-바스킷' 모델 을 소개합니다. 이것은 본질적으로 다대다 관계입니다. 두가지 종류의 엘리먼트 사이의, item 과 baskets 이라고 불리는, 그러나 데이터의 쉐이프에 대한 어떤 가정을 가집니다. 이 빈도 아이템셋 문제는 같은 바구니에 많이 보이는 아이템의 집합을 찾는 문제입니다. 

이 문제는 3단원의 유사도를 찾는 것과는 다른 문제입니다.
여기서 우리는 특정 아이템들의 집합을 포함한 바구니들의 절대 값에 관심이 있습니다. 
3단원에서는 일반적으로 바구니에서 큰 비율 갖는 아이템을 찾았습니다.

이 차이는 이끕니다. 새로운 종류의 알고리즘을, 빈도아이템셋 찾기를 수행하기 위한.
우리는 A-Priori 알고리즘부터 시작합니다. 이는 후보로서 가장 큰 집합을 제거하면서 작동합니다. 더 작은 집합들을 먼저보고, 큰 집합이 그것의 부분집합과 상관없이 빈도가 높을 수 없는 것을 인식합니다.
우리는 A-Priori Algorithm으로 시작합니다. A-Priori Algorithm은 작은 세트를 먼저보고 큰 세트를 후보로 삼아 모든 하위 세트가 아니라면 큰 세트를 자주 사용할 수 없음을 인식하여 작동합니다.
그리고 기본 아이디어에 대한 다양한 개선안들을 고려하고 메인메모리에서 사용 가능한 대규모 데이터셋에 집줍합니다.

그다음, 우리는 추정 알고리즘을 다룹니다. 모든 빈도 아이템셋을 찾는 것은 보장 못하지만 더 빠르게 할 수 있는,
또한 이러한 종류의 알고리즘은, 병렬적으로 할 수 있고, 맵리듀스 공식을 사용할 수 있습니다. 
마지막으로는 어떻게 스트림 데이터에서 찾는지에 대해 간단하게 다룹니다.



## 6.1 The Market-Basket Model

마켓 가방 모델은 물체들의 두 종류들 사이의 다대다 관계의 일반적인 형태를 표현하기 위해 사용됩니다. 
우리는 아이템들을 갖고 있고, 바구니를 갖고 있습니다. 이는 transaction이라고도 불립니다.
각 바구니는 아이템셋으로 구성되어 있습니다. 그리고 일반적으로 우리는 바구니 안의 아이템의 수는 적다고 가정합니다. 전체 아이템의 수에 비해
바구니의 숫자는 일반적으로 매우 크다고 가정합니다. - 메모리에 넣을 수 없을 정도로
데이터는 바구니의 시퀀스로 구성된 파일로 표현됩니다. 
DFS에 따라, 바구니는 파일의 object 이고 각 바구니는 set of items 의 종류입니다.



### 6.1.1 Definition of Frequent Itemsets

직관적으로, 아이템의 집합, 많은 바구니에서, 이를 빈번하다고 합니다.  
포멀하게 만들어봅시다. 우리는 숫자 s 를 가정하고 이는 support threshold 라고 합시다.  
만약 I 가 아이템의 집합이면, I 에 대한 support 를 I 가 부분 집합인 바구니의 수 입니다.  
우리는 I 의 support 가 s 를 넘는다면 이를 *빈번하다* 라고 할 수 있습니다.

example 6.1

<img src="06.Frequent Itemsets.assets/image-20200707111932107.png" alt="image-20200707111932107" style="zoom:50%;" />

그림은 단어들의 집합입니다. 각 집합은 하나의 바구니이고 단어는 아이템 입니다.  
공집합에 대한 서포트는 9입니다. 그러나 일반적으로 공집합은 고려하지 않습니다. 아무런 의미가 없기 때문입니다.  
단일 집합(singleton sets) 중에 {cat},{dog} 은 확실히 빈번합니다. 'Dog'은 5번째 빼고 다 나왔습니다.(support = 7), 'Cat' 은 4,8 번 빼고 나왔습니다.(support = 6)  
'and' 도 많이 나왔습니다.

s=3 으로 두면, 5개의 frequent singleton 아이템셋이 나옵니다. {dot}{cat}{and}{a}{training}

이제 doubleton을 봅시다. doubleton은 그 안에 있는 아이템이 같이 빈번하지 않으면 빈번할 수 없습니다.   
그래서 10개의 가능한 더블톤밖에 없습니다. 

<img src="06.Frequent Itemsets.assets/image-20200707113700929.png" alt="image-20200707113700929" style="zoom:50%;" />

{dog, training} 은 4와 6에서 만 나옵니다. support 는 2 이고 그래서 빈번하지 않습니다.

s=3 인경우 <img src="06.Frequent Itemsets.assets/image-20200707113807297.png" alt="image-20200707113807297" style="zoom:50%;" />

이 쌍들이 빈번합니다.

triples을 봅시다. {dog,cat,a} , {dog,a,and} 등이 있습니다.

이것이 빈번 하려면 그 부분집합이(더블톤) 빈번해야합니다.



#### On-Line vs Brick-and-Mortar Retailing

3.1.3에서 온라인 리테일러는 아이템에 대한 유사도 측정을 사용한다고 제시했습니다. 아이템 쌍을 찾기위해 공통적으로 그 고객들의 중요한 부분을 갖고 있는,  그것들이 많이 팔리지 않을 수도 있지만   
온라인 판매는 그러면, 광고를 할 수 있습니다. 한 아이템 쌍을 일부 고객들에게, 그 쌍의 다른 아이템을 샀었던.  
이러한 방법ㅂ론은 brcks-and-mortar 판매에는 적합하지 않습니다.  
왜냐하면, 아이템을 사는 사람의 수와는 상관없이, 이것은 그 아이탬을 판매하는데 효율적으로 광고를 할 수 없습니다.  
그래서 3단원의 기술은 brcks-and-mortar 상황에 대해 잘 유용하지 않습니다.

반대로, 온라인 소매상은 이 단원에서 이야기할 분석을 필요로합니다.  
왜냐면 이것은 빈번하게 나타나는 아이템셋에 대한 탐색하는 것을 설계하기 때문입니다.   
만약 온라인 판매자가 빈번한 아이템셋으로 제한한다면, 그들은 모든 기회를 놓칠 것 입니다ㅏ. Long tail 에서 제시될 수 있는 고객 개개인에 대한 광고를 선택할 수 있는



### 6.1.2 Applications of Frequent Itemsets

market-basket 모델의 처음 적용사례는 실제 장바구니의 분석하는데 있었습니다.  
슈퍼마켓들이 실제 장바구니의 모든 물품을 기록합니다. 여기서 items 들은 마트에서 파는 여러 물건들이고 basket 은 단일 장바구니의 아이템들의 집합입니다.  
유명체인점에서는 거의 100,000 개의 종류의 아이템들을 팔고, 백만개의 장바구니 데이터가 있습니다.   

빈도 아이템셋을 찾음으로써, 판매자들은 어떤게 주로 같이 팔리는지 알 수 있습니다.   
특히 중요한 것은 쌍들이나 더 큰 아이템 셋들이 있다는 것입니다. 그것은 단일로 사는 것이 기대되는 것보다 더 많이 빈번하게 발생합니다.  
우리는 6.1.3 단원에서 이 문제의 양상에 대해 논합니다. 그러나 그전에 빈도 아이템셋을 찾는 작업을 단순하게 생각해봅시다.   
판매를 할때 핫도그와 머스타드가 같이 잘팔립니다. 핫도그 가격을 낮추고 머스타드 가격을 높이는 방식으로 이득을 얻을 수 있습니다.

이러한 종류의 유명한 예시는 '기저귀와 맥주' 입니다. 두개의 연관성을 기대하기는 어렵지만, 데이터 분석을 통해 한 체인점은 발견했었다. 기지귀를 사는 사람이 일반적으로 맥주를 살 확률이 높다고.  
이 이론은 다음과 같습니다. 만약 기저귀를 산다면, 집에 애기가 있을 것이고, 애기가 있다면, 아마 밖에서 술을 마시기 어려울 것입니다. 그래서 맥주를 집에서 마시는 것입니다.  
우리가 핫도그와 겨자를 위해 제안한 것과 같은 종류의 마케팅 방법은 기저귀와 맥주에 사용될 수 있습니다.  

그러나 빈도 아이템 북성의 적용은 시장에만 제한되지 않습니다.  
다음과 같은 상황에도 사용할 수 있습니다.

1. Related concepts : 아이템이 단어고, 바스켓이 문서가 됩니다.  
   문서는 단어를 포함합니다.  
   만약 우리가 많은 문서에서 나오는 단어의 집합을 찾는다면, 그 집합은 대부분 불용어가 될 것입니다. 이것은 6.1 의 예시에서 볼 수 있습니다.  
   고양이와 개에 대해 이야기하는 발췌문을 찾으려는 의도가 있었음에도 불구하고 자주 사용되는 항목 세트에서 중지 단어 "and"와 "a"가 두드러졌습니다.  
   그러나 만약 모든 불룡어를 무시한다면, 공동적으로 표현하는 단어의 쌍 중 빈도 쌍을 찾을 수 있을 것입니다.  
   예를들면, brad Angelina 와 같이 빈도 쌍이 보여질 것입니다. 
2. Plagiarism : 아이템이 문서들이 되고, 바스켓이 문장들 입니다. 문서는 그 문서 안에 문장이 있다면, 문장 '안' 에 문서가 있습니다.  
   이 배열은 거꾸로 나타나지만 정확히 필요한 것이므로 항목과 바구니 사이의 관계는 임의의 많은 관계라는 것을 기억해야합니다. 즉, "in"은 "part of"라는 일반적인 의미를 가질 필요가 없습니다. 이 응용 프로그램에서는 여러 바구니에 함께 나타나는 항목 쌍을 찾습니다. 그러한 쌍을 찾으면 여러 문장을 공통으로 공유하는 두 개의 문서가 있습니다. 실제로, 하나 또는 두 개의 공통 문장조차 표절의 좋은 지표입니다.
3. Biomarkers :유전자 또는 혈액 단백질과 같은 바이오 마커와 질병이라는 두 가지 유형의 품목을 두십시오. 각 바구니는 환자에 대한 데이터 세트입니다 : 그들의 게놈 및 혈액 화학 분석 및 질병의 병력. 하나의 질병과 하나 이상의 바이오 마커로 구성된 빈번한 항목 집합은 질병에 대한 검사를 제안합니다.



### 6.1.3 Association Rules

1. 이 단원의 주제는 데이터로 부터 빈도 아이템셋을 추출하는 것이지만, 이 정보는 종종 제시됩니다. 'association rule' 이라 불리는 if-then 규칙의 모음으로,  
   이 규칙의 형태는 $I \rightarrow j$ 입니다. I 는 아이템들의 집합이고, j 는 아이템입니다.   
   연관규칙의 의미는 한 바스켓에서 I 안의 모든 아이템들이 나타난다면, j 가 나타날 확률이 높다(likely)는 것입니다.  

2. 우리는 이 'likely' 의 개념을 신뢰도(confidence)를  정의 함으로서 공식화합니다. 신뢰도는  $I \rightarrow j$  는  $I\cup {j}$ 에 대한 서포트와 I 에 대한 서포트의 비율로 정의됩니다.  
   이는 규칙의 신뢰도는 J 또한 포함 하는 I의 모두를 가진 바스켓의 부분이 됩니다.    
   **Example 6.2**   
   규칙 $\{cat,dog\} \rightarrow and$  의 신뢰도는 3/5 입니다. cat, dog 은 5개에서 나왔고 and 는 그중 3개에서 나왔습니다.  
   $\{cat\} \rightarrow kitten$ 는 1/6 입니다. cat 은 6번 나왔고 그 중 kitten 은 (5) 에서만 나왔습니다.

   

3. 규칙의 왼쪽 부분의 서포트가 큰 경우에는, 신뢰도 하나만으로도 유용할 수 있습니다.  
   예를들어 우리는 사람들이 머스타드를 살 때 핫도그를 살 가능이 높다는 것을 알 필요가 없습니다. 이것은 6.1.2 에서 더 이야기합니다.  
   그러나 종종 더 많은 가치가 있습니다. 연관규칙이 실제 관계를 잘 반영한다면, 왼쪽에 있는 아이템들이 오른쪽 아이템에 어느정도의 영향을끼치는지.   

4. 그래서 interest 를 정의 하였습니다.  신뢰도와 j를 포함하는 바스킷의 부분의 차이 입니다. 만약 I 가 j 아무런 영향이 없다면, 우리는 J 가 포함된 I를 포함하는 바스킷의 부분이 j 를 포함한 바스킷의 모든 부분과 동일하다고 예상됩니다.  
   이와 같은 규칙의 interest 는 0 입니다.  
   그러나 다음 상황은 정보적으로나 기술적으로 흥미롭습니다.  
   만약 규칙이 높은 interest 를 갖거나 ( I 가 있는 바스킷에서 어느정도 J 가 발생되는) 높은 음수의 interest 인 경우 (I가 j 를 discourage 하는 것).  
   신뢰도 - 전체중 j 비율.   
   Example 6.3.  
   맥주와 기저귀 예시에서 실제 주장연관 규칙 $\{ diapers\} \rightarrow beer$  는 높은 interest 를 갖습니다.  
   이는 맥주를 산 기저귀 구매자의 부분 전체 맥주를 산사람 중에서의 비율보다 높습니다.

5. ex6.3 설명

### 6.1.4 Finding Association Rules with High Confidence

1. support 임계값 s 이상인 빈도 아이템 셋을 찾는 것이 가능합니다.
2. $I\rightarrow j$ 규칙을 찾으려면, I의 support 가 높아야 합니다. 
3. J가 n개의 빈도 아이템셋의 집합이라면, 연관규칙이 생길 가능성은 n 개 입니다.  다시말해 $J -\{j\} \rightarrow j$ 의 연관규칙만 가능성이 있습니다.  
   J 가 빈번하면,   $J -\{j\}$ 반드시 빈번합니다.
4. 빈번 아이템 셋이 많지 않으면, 연관규칙 후보가 많지 않다.



## 6.2 Market Baskets and the A-Priori Algorithm

### 6.2.1 Representation of Market-Basket Data

1. 마켓-바스켓 데이터를 베스킷 별로 저장할 수 있고, 그 데이터는 dfs에나 기본 파일로 저장할 수 있다.
2. example6.4  
   {23,455,2003} {3,543,234,65} 와 같이 {}는 바스킷, 정수는 아이템으로 표현 할 수 있다.
3. 병렬처리에 대해서는 6.4.4 단원에서 다룬다.
4. 바스킷 파일이 너무 커 메모리에는 못올리고 디스크에서 읽어오면서 사용할 수 있다.  
   바스킷 사이즈가 작은 경우 메모리에서 모든 쌍을 생성할 수 있다.   
   디스크에서 읽어오는 것보다, 쌍을 생성하는 시간이 짧다.
5. 부분집합의 크기가 커지면 (아이템이 많아지면) 시간이 더 크게 소요된다.  
   n개의 아이템에 k 크기의 부분집합을 만드는데 약 $n^k / k!$ 이 소요된다.   
   큰 경우 디스크에서 읽어오는 시간보다 더 오래 걸릴 수 있다.   
   그러나 
   1. 대부분 k=2,3 정도의 빈도 아이템 셋을 요구한다.
   2. 큰 k 를 필요로하는 경우, 빈도 아이템을 찾는 것에 필요없는 많은 아이템 셋을 제거할 수 있다.
6.  검사하는 작업은 파일의 크기에 비례한다고 가정할 수 있다.(k보다는) - 그래서 실행시간을 파일의 디스크 블록을 읽는 횟수에 따라 측정할 수 있다. 
7.  따라서 알고리즘은 바스켓 파일을 통과하는 패스 수를 특징으로 할 수 있으며 실행 시간은 바스켓 파일을 통과하는 패스 수에 해당 파일 크기를 곱한 값에 비례합니다.  
   데이터 크기는 상황마다 다르기 때문에, 알고리즘은 패스의 수를 줄이는 것에 집중합니다.

### 6.2.2 Use of Main Memory for Itemset Counting

1. 
2.  
3.  







### 6.2.5 The A-Priori Algorithm

빈도쌍 찾는거에만 먼저 집중을 해봅시다.   
만약 우리가 메모리가 충분하면 단일패스로 바스켓 파일을 읽으면 된다.  
각 바스켓에대해 우리는 이중루프를 사용한다. 모든 쌍을 만들기 위해서   
각 시간마다 우리는 쌍을 만들고 카운트에 1을 더합니다.  
마지막에는 모든 쌍을 검사합니다. 서포트 임계값 s 보다 더 큰 쌍들을 세기 위해서  

그러나 이러한 단순한 방식은 전체 쌍이 메모리에 다 못 올라가면 사용할 수 없습니다.  
A-Priori 알고리즘은 한 번이 아닌 두 번의 데이터 패스를 수행하여 계산해야하는 쌍의 수를 줄이도록 설계되었습니다.

#### The First Pass of A-Priori

첫번째 패스에서 두개의 테이블을 만듭니다.  
첫번째 테이블을, 만약 필요하다면 아이템의 이름을 1부터 n 사이의 정수로 변환해주는 테이블입니다.  
다른 테이블은 카운트의 배열입니다.   
i 번째 배열의 요소는 i 번호인 아이템이 나타낸 것을 셉니다. 처음에는 0으로 초기화 됩니다.

우리가 바스켓을 읽을 때, 우리는 각 이이템을 보고, 정수로 번역합니다.  
그리고, 정수를 카운트 배열의 인덱스로 사용하고 거기에 1을 더합니다.

#### Between The Passes of A-Priori

첫번째 패스가 끝난 후, 아이템의 카운트를 검사하고 어떤 싱글톤이 빈번한지 결정합니다.  
이곳에서 아마 많은 싱글톤들이 빈번하지 않을 것 입니다.  
우리는 s 를 충분히 높게 설정해서, 너무 많은 빈도집합은 얻지않도록 했습니다. 일반적으로 s 는 바스켓에서 1% 정도 될 것입니다.  

두번째 패스에 대해, 우리는 새로운 넘버링을 만듭니다. 빈도 아이템들에 대해 1부터 m 까지  
이 테이블은 1부터 n 까지로 인덱스된 배열이고,   
i 에 대한 엔트리는 i 가 빈번하지 않으면 0 이고, 아니면, 1부터 m 까지의 유일한 정수를 갖습니다.  
우리는 이 테이블을 frequent-items table 이라고 합니다.

#### The Second Pass of A-Priori

두번째 패스동안에는, 두개의 빈도 아이템으로 구성된 모든 쌍을 셉니다.  
6.2.3 에서 그것의 멤버가 빈번하지 않다면, 그 쌍이 빈번하지 않다고  하였습니다.  
그래서 우리는 빈번하지 않은 쌍을 놓지지 않았습니다.    
두번째 패스에서 필요한 공간은 $2m^2$ 바이트입니다. 2n^2 보다 작습니다.  
빈번한 아이템들에 대한 리넘버링은 필요합니다. 우리가 만약 삼각행렬을 올바르게 사용하기 위해서는  
첫번째와 두번째 패스에서 사용된 매인메모리의 구조의 complete set 은 6.3과 같습니다. 

<img src="06.Frequent Itemsets.assets/image-20200709172623178.png" alt="image-20200709172623178" style="zoom:50%;" />

또한, 빈번하지 않은 아이템을 제거하는 것의 이점은 극대화 됩니다. : 만약 아이템 절반이 빈번하면 계산 공간이 1/4 만 필요합니다.  
또한, 만약에 트리플 방식을 사용한다면, 적어도 하나의 바스켓에서 나타난 두개의 빈도 아이템 쌍들만 세면 됩니다. 

두번째 패스의 매커니즘은 다음과 같습니다. 

1. 각 바스켓에 대해, 그것의 아이템들이 빈번한지 보기 위해 freq-item table을 봅니다. 
2. 이중 루프로, 바스켓에있는 모든 빈도 아이템의 쌍을 발생시킵니다.
3. 각 패어들에 대해, 카운트를 저장하기 위해 사용된 데이터 구조에 그것의 카운트에 1을 더합니다. 

2번째 패스 끝에서 쌍들이 빈번한지 결정하기 위해 카운트의 structure 를 검사합니다.



### 6.2.6 A-Priori for All Frequent Itemsets

모든 쌍을 계산하지 않고 빈번한 쌍을 찾는 데 사용 된 것과 동일한 기술을 사용하면 모든 집합을 모두 계산하지 않고도 더 큰 빈번한 항목 세트를 찾을 수 있습니다  
이 알고리즘에서, 첫번째 패스는 각 집합의 크기 k 에 대해  취해집니다@.  
만약 특정 크기의 아이템셋이 빈번하지 않는다면, monotonicity 는 더 큰 빈도 아이템셋 이 없다는 것을 말하고, 우리는 멈춥니다.  

한 크기 k에서 다음 크기 k 1로 이동하는 패턴은 다음과 같이 요약 할 수 있습니다.  
각 크기 k에 대해 두 세트의 항목 세트가 있습니다.

1. $C_k$ 는 k크기의 후보 아이템셋들의 집합입니다. - 아이템셋은 우리가 그것이 실제로 빈번한지 결정하기 위해 세어야 합니다. 
2. $L_k$ 는 k 크기의 실제 빈도 아이템셋의 집합입니다.

한 집합에서 다음으로 가는 패턴은 다음과 같습니다.

<img src="06.Frequent Itemsets.assets/image-20200709174458575.png" alt="image-20200709174458575" style="zoom:50%;" />

C1 에서 시작하고 모두 싱글톤입니다. 데이터를 검사하기전, 어떠한 아이템도 빈번해질 수 있습니다.   
첫번째 필터 스텝은 모든 아이템을 세는 것입니다. 그리고 이 카운트 중 s 가 넘는 것들이 집합 L1 이 됩니다.

C2 집합은 L1의 아이템에서 만들 수 있는 쌍입니다. L1에 둘다 있는 멤버인지 검사하면서 C2의 멤버를 검사합니다.  
알고리즘의 두번째 패스는 모든 후보쌍을 세고, s 번 이상 나온 것들을 정합니다.  그 쌍은 L2를 형성합니다. (빈도 쌍인)

우리는 이 패턴을 따를 수 있습니다. C3 는 L2안에 있는 쌍의 어떤 두개짜리가 삼중의 집합으로 구성할 수 있는 후보 트리플의 집합입니다.  
빈도 아이템셋의 sparsity에 대한 가정은 암시합니다. 여기 그렇게 많은 빈도 쌍은 없다고, 그래서 메모리테이블에 나열할 수 있다는 것을.  
이와 같이, 그리 많은 3중 후보쌍은 없을 것입니다. 그래서 삼중에서도 충분히 일반화로 계산할 수 있습니다.   
즉, 트리플은 쌍을 계산하는 데 사용되지만 트리플을 계산하려면 세 개의 항목 코드와 관련 카운트로 구성된 쿼드 러플을 사용합니다. 마찬가지로, 우리는 k 1 개의 구성 요소가있는 튜플을 사용하여 크기 k 세트를 계산할 수 있습니다.

L3을 찾기 위해 바스켓 파일을 세 번째로 통과했습니다. 각 바구니마다 L1에있는 항목 만 살펴보십시오. 이러한 항목에서 각 쌍을 검사하고 해당 쌍이 L2에 있는지 여부를 확인할 수 있습니다. 바스켓에있는 품목으로 구성된 둘 이상의 빈번한 쌍으로 나타나지 않는 바스켓 품목은 바스켓에 포함 된 잦은 트리플의 일부가 될 수 없습니다. 따라서 바구니에 포함되어 있고 C3의 후보 인 트리플에 대한 검색은 상당히 제한적입니다. 발견 된 트리플은 1을 더했습니다.

더 큰 빈발 항목 집합과 후보자 집합의 구성은 어떤 통행에서 새로운 빈발 항목 집합을 찾을 수 없을 때까지 본질적으로 동일한 방식으로 진행됩니다. 다음과 같이

1. Ck 를 정의합니다. 크기가 k 인 모든 아이템이 되는, 모든 k-1 은 Lk 에 있습니다. 
2. LK를 찾습니다. 바스켓을 패스하면서 CK에 있는 아이템셋만 세면서, 카운트가 s 이상인 것들이 Lk입니다.





### 6.3.1 The Algorithm of Park, Chen and Yu

이 알고리즘은 첫번째 패스에서 사용되지 않는 메인 메인메모리거 있다는 것을 활용한 방식입니다.  
백만개의 아이템이 있고 메모리가 GB 단위라면, 우리는 테이블을 위한 공간이 메모리의 10% 정도 밖에 필요하지 않습니다. - item 이름을 정수로 변환하기 위한 테이블과, 그 정수(아이템) 의 카운트 테이블.  
PCY 알고리즘에서는 블룸 필터 컨셉을 일반화한 정수들의 배열을 위한 공간을 사용합니다.  
이 개념은 다음과 같이 도식화할 수 있습니다.

<img src="06.Frequent Itemsets.assets/image-20200712164045952.png" alt="image-20200712164045952" style="zoom:50%;" />

이 배열을 해시 테이블로 생각해봅시다. 여기서 버킷은 키들의 집합이나 비트 대신 정수들을 갖습니다.  
아이템들의 쌍은 해시 테이블의 버킷으로 해시됩니다.  
첫번째 패스에서 버킷을 검사하면서, 우리는 각 버킷에 있는 아이템의 카운터에 1을 더할 뿐 아니라, 모든 쌍을 생성합니다.(이중 루프로).  
우리는 각 쌍을 해시하고 쌍이 해시된 버킷에 1을 더합니다. 그 페어 자체가 버킷에 들어가는 것이 아닙니다. 그 쌍은 버킷의 단일 정수에게만 영향을 끼칩니다. 

첫번째 패스 마지막에, 각 버킷은 카운트를 갖습니다. 이 것은 그 버킷으로 해시된 모든 페어들의 카운트의 합입니다. 한 버킷의 카운트가 적어도 s 보다 크다면, 이것을 'frequent bucket' 이라고 합니다.  
빈번한 버킷으로 해시되는 쌍에 대해서는 아무 것도 말할 수 없습니다. 그들은 우리가 이용할 수있는 정보에서 모두 자주 쌍을 이룰 수 있습니다.  
그러나 버킷이 s 이하로 카운트되면, 그 버스킷에 빈번해질 수 있는 쌍이 없다는 것을 압니다. 비록 그 쌍이 두개의 빈번한 아이템으로 구성되어 있다하더라도.   
이것은 두번째 패스 때 이점을 줍니다. 후보쌍 C2 에 대한 정의를 다음과 같이 바꿀 수 있습니다.

1. i 와 j 는 freqent item 이다. 
2. {i,j} 가 frequent bucket 에 해시된다.

이 두번째 조건이 A-Priori 와 PCY 의 차이입니다.

PCY의 패스들 간에, 해시테이블은 bitmap으로 요약됩니다. 각 버켓에 대대 하나의 비트로.  
만약 버킷이 빈번 하면 bit가 1 이고, 아니면 0 으로 됩니다.  
그래서 32bit의 정수는 단일 bit 로 대체됩니다. 그리고 비트맵은 6.5 그림과 같이 기존의 1/32 의 공간만 차지합니다.  
대부분의 버켓이 infrequent 하다면, 두번째 패스에서 계산되는 전체 페어가 많이 줄어들게 됩니다.   
그래서 PCY 는 두번째 패스에서 낭비없이 데이터 셋을 다룰 수 있습니다. 

필요한 공간의 양에 영향을 미치는 PCY의 두 번째 패스와 관련하여 신경 쓸 것이 있습니다.  
A-priori 에서는 두번째 패스에서 삼각행렬을 사용하는 것이 가능했지만(1-m 으로 리넘버링 하면서), PCY 에서는 쓸 수 없습니다.   
그 이유는 빈도 아이템들의 패어는 (PCY가 카운팅을 피하도록 한) 삼각행렬안에 있는 임의로 위치합니다.  그것들은 첫번째 패스의 빈번하지 않은 버킷으로 해시가 발생한 패어입니다.   
압축된 행렬이 카운트되지 않은 쌍에 대해 남겨진 공간을 피하는 방법이 없습니다. 

결과적으로 우리는 PCY 에서는 트리플방식만 써야합니다.  
이 제약은 실제 아이템이 많이 나오지 않는 경우에는 중요한 문제가 되지 않을 수 있지만, 하나의 버스켓에서 많은 쌍이 빈번하게 나오는 경우는 비효율적입니다.  
그래서 PCY 가 적어도 2/3 의 쌍을 카운팅하는 것을 줄여주지 않는다면 A-Priori 대신 PCY 를 쓰는 이점이 없습니다.  

PCY에 의한 빈번한 쌍의 발견은 A- Priori와 크게 다르지만, 빈번한 트리플과 더 큰 세트를 찾는, 이후의 단계는 본질적으로 A-Priori와 동일합니다.   
이와 관련된 내용은 다른 다시 섹션에서 다룹니다. 여기서는 pair 에 대해서만.



### 6.3.2 The Multistage Algorithm

멀티스테이지 알고리즘은 PCY 기반으로 몇개의 연속적인(successive) 해시 테이블을 사용해 후보쌍의 수를 더 줄이는 알고리즘입니다.  
여기서 트레이드오프는 멀티스테이지가 빈도쌍을 찾기 위해 2개 패스 이상이 필요하다는 것입니다.  
대략적인 도식도는 다음과 같습니다.  

<img src="06.Frequent Itemsets.assets/image-20200714203212776.png" alt="image-20200714203212776" style="zoom:50%;" />

멀티스테이지의 첫번째 패스는 PCY 와 같습니다.   
그 패스 다음에, 빈도 버킷은 비트맵으로 요약합니다.(여기도 PCY) 와 같습니다.  
멀티스테이지에서 두번째 패스는, 후보쌍을 세지 않습니다.  
대신, 남은 메인메모리를 다른 해시 함수를 사용한 해시 테이블을 위한 공간으로 사용합니다.  
첫번째 해시 테이블의 비트맵이 가용 메모리의 1/32 을 사용하기 때문에, 두번째 해시 테이블도 거의 첫번째와 유사한 크기를 갖습니다.

멀티스테이지의 두번째 패스에서, 우리는 다시 바스켓의 파일을 훑습니다.  
아이템을 다시 카운트 할 필요는 없습니다. 첫번째 패스서 이미 카운트 했기 때문입니다.  
그러나 우리는 반드시 정보를 갖고 있어야 합니다. 빈번한 아이텝들에 대한 정보를, 왜냐하면 두번째와 세번째 패스 모두에 필요하기 때문입니다.  
두번째 패스동안, 우리는 아이템들의 특정 쌍들을 해시해서 두번째 해시 테이블의 버킷에 담습니다.  
쌍은 오직 PCY에서 두번째 패스에서 카운트 되기 위한 두가지 조건을 만족할 때 해시됩니다. 조건 1 - 아이템 i,j 가 둘다 빈번할 때 {i,j}를 해시합니다.  
조건 2 - 그 쌍이 첫번째 패시의 빈도 버킷에 해시되어 있는 것일 때만 해시합니다.  
그 결과, 두번째 해시 테이블의 카운트의 합은 매우 적습니다.(첫번째 패스보다)  
이는, 두번째 해시 테이블이 첫번째 버킷의 수의 31/32 만 갖고 있더라도, 첫번째 보다 두번째가 훨씬 더 적다는 것을 기대할 수 있습니다.  

두번째 패스 후에는, 두번째 해시 테이블은 비트맵으로 요약되고, 그 비트맵은 메모리에 저장됩니다.  
두 비트맵 모두 가용 메모리의 1/16 보다 적게 차지합니다. 그래서 3번째 패스에서 후보쌍을 저장하기 위한 공간은 여전히 충분합니다.  
여기서 C2 안의 쌍 {i,j} 는 다음과 같습니다.

1.  i,j 모두 frequent items 이다
2. {i,j}가 첫번째 해시테이블에서 frequent bucket 으로 해시되었다.
3. {i,j}가 두번째 해시테이블에서 frequent busket 으로 해시되었다.

여기서 3번째 조건이 멀티스테이지와 PCY 의 구별점입니다.

멀티스테이지 알고리즘에서 첫번째와 마지막 패스 사이에 어떤 수든 넣어도 가능하다는것은 명백할 것입니다.  
이전 패스들의 각각으로부터의 비트맵이 각각의 패스에 반드시 저장되어야하는 것이 제약조건입니다.  
결국, 메모리가 카운트하기위한 충분한 공간이 남지않게 될 것입니다.  
얼마나 많은 패스를 사용하는지는 중요하지 않습니다.  
실제 빈도 쌍은 항상 빈도 버킷에에 해시되고, 그래서 그것들을 카운팅을 피하는 방법은 없습니다.

#### A Subtle Error in Multistage

때때로, 구현에서 후보가 되기위한 두번째 조건을 제거하기도 합니다.(첫번째 패스서 해시된 빈도 버킷). 그러는 이유는 만약, 첫번째 패스에서 빈도 버킷으로 해시되지 않는 경우, 두번째 패스에서 해시될 수 없게 됩니다.  그래서 두번째 패스에서 그것의 버킷 카운트에 기여할 수 없게 됩니다.  
그 쌍이 두번째 패스에서 카운트되지 않는 것은 사실이지만, 이것이 해시된 빈도 버킷이 해시되지 않는다는 것을 의미 하지 않는다는 것이 아닙니다.  
그래서, 두개의 빈도 아이템으로 구성되었고 두번째 패스에서 빈도 버킷으로 해시되었지만, 첫번재 패스에서 해시되지 않는 {i,j} 가 있다는 것이 가능합니다.  
그러므로 세번째 조건은 멀티스테이지의 패스 카운팅에서 반드시 거쳐야합니다.



### 6.3.3 The Multihash Alogrithm

때때로, 단일 패스에서 멀티스테이지 알고리즘의 여러 패스에서의 이점의 대부분을 얻을 수 있습니다. 이 PCY 의 변종을 Multihash algorithm 이라고 합니다.  
두개의 연속된 패스에서 두개의 다른 해시테이블을 사용하는 대신, 두개의 해시 함수와 분리된 해시테이블을 사용합니다. 6.7 처럼

<img src="06.Frequent Itemsets.assets/image-20200714223905913.png" alt="image-20200714223905913" style="zoom:50%;" />

한 번에 두 개의 해시 테이블을 사용하는 위험은 각 해시 테이블이 PCY의 하나의 큰 해시 테이블보다 절반의 버킷을 가지고 있다는 것입니다.  
PCY 에 버킷의 평균 카운터가 임계값보다 훨씬 낮은 한, 우리는 두개의 절반크기의 해시테이블을 사용할 수 있고, 여전히 두 해시 테이블의 버킷의 대부분이 빈번하지 않을 것이라는 것을 기대할 수 있습니다.  
그래서 이 상황에서 우리는 멀티해시 접근법을 사용할 수 있습니다.

멀티해시에서 두번째 패스에서, 각 해시테이블은 비트맵으로 바뀝니다. 두개의 비트맵은, 정확히 하나의 비트맵의 크기를 차지합니다. (PCY에서 단일 비트맵 크기의)  
C2 개 되기 위한 조건, 두번째 패스에서 필요한 카운트 요구는, 멀티스테이지에서 세번째 패스에서와 동일합니다.  - 아이템 둘다 빈번하고, 그 쌍이 두개의 해시 테이블에 따른 빈도 버킷으로 해시된 쌍이여야합니다.

멀티스테이지가 두개의 해시테이블에 대해 제약이 없는 것 처럼, 우리는 가용 메모리를 첫번째 패스에서 여러개의 해시테이블로 나눌 수 있습니다.  
해시 테이블을 너무 많이 사용하면 버킷의 평균 수가 지원 임계 값을 초과 할 위험이 있습니다. 그 지점에서, 아마 많우 적은 빈번하지 않은 버킷이 있을 것입니다.  
계산할 모든 해시 테이블에서 페어가 빈번한 버킷으로 해시되어야하지만 다른 해시 테이블을 추가 할 경우 빈번하지 않은 페어가 후보가 될 가능성이 높아질 가능성이 있습니다.