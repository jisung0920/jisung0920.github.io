# 15. Query Processing

쿼리 프로세싱은 데이터베이스로 부터 데이터를 추출(extracing)하는 것과 관련있는 엑티비디들의 범주를 이야히 합니다.  
이 엑티비디들은 고수준 디비 언어의 쿼리들에서 파일 시스템의 피지컬 수준에서 사용되는 표현으로의 트랜스래이션을 포함합니다. 또 다양한 쿼리 옵티마이징 변환과 실제 쿼리 평가를 포함합니다.

## 15.1 Overview 

<img src="DB_15_Query Processing.assets/image-20200808133714693.png" alt="image-20200808133714693" style="zoom:50%;" />

위 그림은 쿼리를 처리하는 스텝을 나타냅니다.   
기본적인 스텝은 다음 3개입니다.

1. Parsing and translation 
2. Optimization
3. Evaluation

쿼리 프로세싱이 시작되기 전에, 시스템은 쿼리를 사용가능한 형태로 번역하는 것이 필요합니다.   
SQL 과 같은 언는 사람이 사용하기 적합하지만 시스템 내부적으로 쿼리를 표현하기는 부적합합니다.  
내부적인 표현에는 관계대수를 확장시킨 방식이 더 유용하게 동작합니다.

그래서 시스템은 우선 쿼리를 내부적인 폼으로 번역합니다.  
이러한 번역과정은 컴파일러의 파서가 수행하는 작업과 유사합니다.  
쿼리의 내부적인 폼을 생성하는 과정에서, 파서는 사용자의 쿼리의 syntax 를 확인하고,  
쿼리안의 릴레이션이 디비에서 릴레이션의 이름으로 나타나는 등의 작업을 검증합니다.  
시스템은 쿼리의 파서 트리 표현(parse-tree representation)을 구성합니다.  이것은 파서를 관계 대수 표현으로 변환한 것입니다.   
만약 쿼리가 뷰의 term 들 안에서 표현되었다면, 번역 phase 는 뷰를 정의한 관계 대수 표현으로 모든 뷰의 사용을 대체합니다. 대부분의 컴파일러 텍스트는 세부적으로 파싱을 다룹니다.(cover)

한 쿼리가 주어지면, 일반적으로 이를 번역하는 방법은 다양하게 있습니다.   
예를 들어, SQL에서 한 쿼리는 다양한 방법으로 표현이 됩니다.  
각 SQL 쿼리들은 여러 방법 중의 하나로 특정 관계대수 표현으로 번역될 수 있습니다.  
일반적으로 관계 대수 표현을 평가흔 여러 방법이 있고, 한 쿼리에 대한 관계 대수 표현은 어떻게 쿼리를 평가하는지에 대해 일부분만 명시합니다.   
다음과 같은 상황을 고려해보면  

```sql
SELECT salary
FROM instructor
WHERE salary < 7500		
```

위 쿼리는 다음과 같은 두개의 관계 대수로 표현할 수 있습니다. 

- $\sigma _{salary <7500} ( \Pi_{salary} ( instructor))$
- $\Pi_{salary} (\sigma _{salary<7500}(instructor))$

그리고, 각 관계 대수 연산들은 여러 다른 알고리즘 중 하나를 사용해 실행시킬 수 있습니다.  
예를 들어, 먼저 수행하는 selection 을 구현할 때, 7500 보다 작은 salary 의 튜플을 찾기 위해서 instructor 에서 모든 튜플을 찾을 수 있습니다.  
B+ tree index 는 salary 속성에 대해서 사용할 수 있고, 이를 통해 튜플의 위치 대신 index 를 사용해서 빠르게 찾을 수 있습니다.

어떻게 쿼리를 평가하는지 구체적으로 이야기하기위해,  
관계 대수 표현을 제공할 뿐 아니라 각 연산에 대해 평가하는 방법을 지정하는 명령어를 표기해야합니다.  
표기들은 알고리즘이 특정 연산이나 사용하는 특정 인덱스에 대해 어떻게 사용될지에 대해 진술합니다.  
어떻게 평가할지에 대한 명령어를 가진것이 표기된 관계 대수 연산은 evaluation primitive 로 불립니다.   
한 쿼리를 평가하기 위해 사용되는 evaluation primitive의 시퀀스는 query-execution plan, query-evaluation plan 으로 불립니다.

<img src="DB_15_Query Processing.assets/image-20200808142104905.png" alt="image-20200808142104905" style="zoom:50%;" />

위 그림은 이전 예시에 대한 query-execution plan 입니다.  
이 plan 을 수행하는 것을 query-execution engine 이라고 합니다. plan 을 실행(execute)하고 쿼리에 대해 답을 리턴합니다.

주어진 쿼리에 대해 다른 evaluation plan 은 서로 다른 코스트를 갖을 수 있습니다.  
일반적으로 사용자는 효율적인 plan 으로 쿼리를 작성하지 않습니다.  
때문에 query-evaluation plan 을 최소한의 코스트가 발생하도록 구성하는 것은 시스템의 역할이고,   
이 작업을 query optimization 이라고 합니다.

일단 쿼리 플랜이 선택되면 쿼리는 플랜을 가지고 평가됩니다. 그리고 그 쿼리의 결과가 output 입니다.  

처리하는 한 쿼리에 대해 이미 설명된 스텝들의 시퀀스는 representative 입니다.  
모든 디비들이 이러한 스텝을 따르지는 않습니다.  
예를 들어, 몇 디비들은 관계 대수 표현을 사용하는 대신 SQL 쿼리의 구조에 기반한 parse-tree 표현을 사용합니다.    
그러나 여기서 설명하는 것은 query processing 의 기초를 다룹니다.  

쿼리를 최적화하기 위해서, 쿼리 옵티마이져는 각 연산의 코스트에 대해 알고 있어야 합니다.  
연산을 위한 가용 메모리와 같은 파라미터 등에 의존적이기 때문에 정확한 코스트를 계산하는 것은 힘들지만, 각 연산에 대해 대략적으로 실행 코스트를 추정할 수는 있습니다.

여기에서는 쿼리 플랜에 있는 각 연산들을 어떻게 평가할지와 그 코스트를 어떻게 추정할 지에 대해 다룹니다.     
15.2에서는 한 쿼리의 코스트를 어떻게 측정할지,   
15.3~6에서는 개별적인 관계 대수 연산을 평가하는 것에 대해 다룹니다. 몇몇 연산들은 하나의 pipeline으로 그룹됩니다. 연산들의 다른 연산에서 생성된 경우에서 그것의 입력 튜플에서 같이 작업을 시작합니다.   
15.7에서는 쿼리 평가 계획에서 다중 연산의 실행을 어떻게 조정하는지 확인하고, 특히 디슼크에 imtermediate result 없이 파이프된 라인 연산을 수행하는지에 대해 다룹니다. 

## 15.2 Measures of Query Cost

한 쿼리에 대해 가능한 평가 플랜들은 다양합니다.   
그리고 여러 플랜들의 추정된 코스트를 비교하여 최적의 플랜을 선택하는 것이 가능합니다.    
그렇게 하기 위해서는 먼저 개별 연산들의 코스트와 그것들을 합쳤을 때 의 코스트를 추정해야합니다.  
그래서 이후 챕터에서 각 연산에 대한 평가 알고리즘을 다룰 때,  그 연산의 코스트를 어떻게 추정하는지 대략적으로 확인할 수 있습니다.   

쿼리 평가의 코스트는 여러 다른 리소스 관점으로 측정될 수 있습니다.  disk access, CPU, parallel, communiation 등이 있습니다.  

마그네틱 디스크에 있는 대규모 디비에 대해서는, 데이터에 접근하는  IO 코스트 가 지배적인 코스트입니다.    
그래서 초기 코스트 모델은 IO 코스트에 포커스를 맞추었습니다.   
그러나 flash 스토리지나 SSD 를 사용하면서 그 비용이 줄었고,  
in-memory 나 SSD 에 있는 데이터에서는  IO 코스트가 전체 코스트에 지배적이지 않습니다.  
그리고 CPU 코스트가 쿼리 평가의 코스트를 계산하는데 중요해졌습니다.  
여기서는 코스트를 단순화하기 위해서 CPU 코스트를 포함하지 않지만, 그것들은 단순한 esimator 로 추정될 수 있습니다.  
예를 들어, PostgreSQL 에서 사용된 코스트 모델은 다음을 사용합니다.

1. 튜플 당 CPU 코스트
2. 각 인덱스 엔트리 프로세싱에 대한 CPU 코스트
3. 연산자나 함수 당 CPU 코스트   

이 디비는 이러한 코스트들 각각에 대해 디폴트 값을 갖고 있습니다.  
이것은 각각  1.처리된 튜플의 수 2.처리된 인덱스 엔트리의 수 3.수행된 연산자, 함수 의 숫자 에 의해 곱해집니다.   
디폴트는 configuration parameter 에 의해 바뀔 수 있습니다.

여기서는 스토리지로 부터 보내진 블록의 수와 random IO access 의 수를 사용하여 쿼리 평가 플랜의 코스트를 추정합니다.  - 이것들 각각은 저장소에 대한 disk seek 을 요청합니다.  
만약 disk subsystem 이 데이터 블록 하나를 전달하는데  평균 $t_T$ 초 정도 걸리고  
평균  $t_s$ 의 block-acess time 이 필요하다면  
b 블록을 이동하고 S 개의 랜덤 IO access 가 수행하는 연산은 $b\times t_T + S \times t_S$ 초가 설립니다.  

t 값들은 사용하는 디스크 시스템에 대해 보정되어야 합니다.   
12쳅터에 퍼포먼스가 요약되어있습니다.   
하이엔드 마그네틱 디스크에 대해, 일반적인 값은(2018년도 기준) 4kb 블록의 사이즈를 40MB/s 로 전송하였을 때  $t_S$ = 4ms, $t_T$=0.1ms 입니다. 

SSD 가 물리적으로 seek 연산을 수행하진 않지만, IO 연산을 초기화하기 위한 오버헤드가 있습니다.  
IO 리퀘스트가 만들어진 시간부터 데이터의 첫번째 byte 가 리턴된 시간의 latency 를 $t_S$ 로 둡니다.   
mid-range SSD, SATA 인터페이스를 사용한 rjtemfdms t_S 가 약 90 마이크로초가 소요되었고,   
t_T 는 약 10 microsecond 가 소요되었습니다. (4-KB 블록에 대해)  
그래서 SSD 는 1초당 약 10000개의 랜덤 4KB read 를 수행할 수 있습니다. 그리고 시퀀스 read 에 대해 400mb/s 의 throughput을 지원합니다.  
이와 같이 PCIe 를 사용한 SSD 는 더 좋은 성능을 보입ㄴ디ㅏ. 

메모리에 이미 있는 데이터들에 대해, read는 캐시 라인들의 단위에서 발생합니다.  
그러나 데이터 의 전체 블록을 읽는 것을 가정하면, 전송을 위한 시간 $t_T$ 는 1마이크로초보다 더 작습니다.   그리고 $t_S$ 는 100 나노초보다 더 작습ㄴ디ㅏ.

다른 스토리지 디바이스들의 속도가 다양하게 주어진다면, 디비시스템은 소프트웨어 설치 과정의 일부로서 , 시스템, 스토리지 장비 에 대한 $t_S$ 와 $t_T$ 를 추정하는 test 를 수행해야 합니다.     
이러한 수치를 자동적으로 추론하지 않는 디비들은 종종 사용자에게 configuration 파일들의 일부로서 수치들을 명시하도록 합니다.  

block write 로 부터 block read 를 구분하여, 코스트 추정을 더 정제할 수 있습니다.  
block write 는 마그네틱에서 일반적으로 read 보다 2배의 비용이 듭니다.  
이는 디스크 시스템에서 섹터를 읽고 이후에 write 가 성공적인지 검증해야하기 때문입니다.   
PCIe 플래시에서는 write throughput 이 read throughput 보다 50% 정도 적게 나옵니다.  
SATAT 에서는 write 와 read 의 throghput 이 비슷합니다.    
그러나 이 throghput 수치는 erase의 코스트를 반영하지 않습니다. (overwritten 시) - 단순화하기 위해서, 이러한 디테일은 무시합시다. 

코스트 추정들은 연산의 최종 결과가 디스크로 돌아가 쓰는 코스트를 포함하지 않습니다.  
이러한 것들은 요청된 곳에 따라 비용이 차이가 있습니다.  
우리가 고려하는 전체 알고리즘의 코스트는 메인 메모리에서의 버퍼의 크기에 달려있습니다.(depend on).  
best case 에서는, 데이터가 버퍼에 들어갈 수 있다면, 데이터가 버퍼에서 읽을 수 있고, 디스크에 다시 접근할 필요가 없는 것 입니다.  
최악의 경우는,   버퍼가 몇개의 블록만 유지할 수 있고, relation 당 하나의 블록이 필요한 것 입니다.  
그러나 오늘날 메인 메모리가 커져서, 이러한 워스트 케이스는 잘 발생하지 않습니다.  
사실상, 일반적으로 쿼리를 처리하는 데 많은 양의 주 메모리를 사용할 수 있습니다. 그리고 코스트 추정은 하나의 연산자 M 에 대해 가능한 메모리의 양을 사용합니다.   
PostgreSQL 에서, 하나의 쿼리에 대한 전체 가용 메모리는 effective cache size 라고 불립니다. 그리고 이것은 디폴트로 4GB를 가정합니다.  (코스트 추정의 목적으로)  
만약 쿼리가 여러개의 연산자들을 동시에(concurrently) 갖는다면, 가용메모리는 연산자 간에 나눠야 합니다.

추가적으로, 초기에 디스크로 부터 데이터를 반드시 읽어야 한다고 가정하지만, 블록이 이미 메모리 버퍼에 존재할 수 있습니다.  
단순히하기 위해서 이러한 영향은 무시합니다.  
그 결과, 실제 하나의 플랜에서 실행되는 동안의 disk-access  cost는 추정된 코스트보다 조금 더 작을 것입니다.  
버퍼에 상주하는 것에 대해 계산하기 위해, PostgreSQL 은 hack 를 사용합니다.  
: random page read 의 비용을 실제 read 의 비용에 1/10 으로 두고, 9/10 을 캐시에 있는 상황으로 가정합니다.   
또한 B-tree 인덱스의 내부 노드가 자주 순회되는 상황을 모델링하기 위해, 대부분의 디비시스템은 모든 내부 노드가 인메모리 버퍼에 있는 것으로 가정하고, 인덱스 순회는 리프노드에 대해 하나의 random IO 에서만 발생한다고 가정합니다.  
쿼리 평가 플랜에 대한 response time 은 이러한 모든 코스트들의 총 합이고, 이 플랜의 코스트의 측도(measure)로 사용될 수 있습니다.  
그러나 이러한 플랜의 reponse time 실제 plan 실행 없이는 추정하기가 매우 어렵습니다.   
그 이유는 다음과 같습니다.

1. reponse time 은 쿼리가 시작했을 때의 버퍼의 contents에  따라 다릅니다. (depend on)  
   이 정보는 쿼리를 최적화하는데에서 사용할 수 없고 사용할 수 있더라도 계산하기가 어렵습니다.
2. 하나의 시스템의 다중의 디스크가 있는 경우, reponse time 은 분산된 디스크에 대해 어떻게 접근하느냐에 따라 달려 있습니다.  
   이것은 디스크에 있는 데이터 레이아웃에 대한 세부적인 정보 없이는 추정하기 어렵습니다.

하나의 플랜은 extra 리소스 consumption 에 대한 더 나은 reponse time 을 갖을 수 있습니다.  
예를들어, 만약 다중 디스크를 가진 하나의 시스템에서, extra 디스크 read 를 요구하지만 그 read 를 병렬적으로, 다중 디스크에서 수행하는 플랜 A 는,  
disk read 가 적지만 하나의 디스크로만 read 하는 플랜 B 보다 빠를 수 있습니다.   
그러나 A 를 사용하는 쿼리의 여러 인스턴스가 동시에 실행되는 경우,  
A가 디스크에 더 많은 로드를 생성하므로, 전체 응답 시간이 실제로 플랜 B를 사용하여 동일한 인스턴스를 실행하는 것보다 더 길 수 있습니다.

그래서, respone time 을 최소화 하는 것보다는, 일반적으로, optimizer 는 쿼리 플랜에서 전체 resource comsumption 를 최소화 하는 것을 시도합니다.  
전체 디스크 접근 시간(seek+transfer)을 추정하는 우리의 모델은 쿼리 코스트의 resouce consumption-based model 의 예시 입니다.



15.3 Selection Operation 

15.4 Sorting 

15.5 Join Operation

15.6 Other Operations

15.7 Evaluation of Expressions 

15.8 Query Processing in Memory 

15.9 Summary

- 단순 selection 연산은 linear scan 이나 index 를 만들어 사용해서 수행할 수 있다.  
  복잡합 selection 은 simple selection 의 union 이나 intersection 으로 다룰 수 있다.  
- 메모리보다 큰 경우 external sort-merge 알고리즘을 사용하여 sort 할 수 있다. 
- natural join 을 포함하는 쿼리들은 relation 에 대한 물리적 스토리지의 형태와 index availability 에 따라 여러 방법으로 처리될 수 있다.
  - 만약 join 의 결과가 두 relation의 Cartesian 곱 정도로 크다면, block nested-loop join 을 사용하는 것이 좋다. 
  - index 를 사용할 수 있다면, indexed nested-loop join 을 사용할 수 있다.
  - relation 이 정렬되어 있다면, merge join 이 좋다. - join 에 앞서 relation을 sort 하는 것이 좋다.
  - hash join algorithm 은 relation 을 여러 조각으로 나눈다. 그래서 한 relation 의 각 조각들은 메모리에 들어갈 수 있다.  
    분할은 해시함수로 수행되고, 이는 join attribute 를 사용해서 분할들의 쌍은 각각 join 된다.
- duplicate elimination, projection, set operation, aggregation 은 sorting 이나 hashing 으로 수행될 수 있다.
- outer-join 연산은 join 알고리즘의 단순한 확장으로 구현될 수 있다.  
- hasing 과 sorting 은 dual 이다.  duplicate elimination, projection, set operation, aggregation  과 같이 hasing 으로 구현할 수 있는 모든 작업은 sorting으로 구현할 수 있고, 그 반대도 성립한다.  
- expression 은 materialization 의 방식으로 평가 될 수 있습니다. 시스템은 각 subexpression 의 결과를 계산하고, 이것을 디스크에 저장하여 parent expression 의 결과를 계산하는데 사용합니다.
- Pipelining 은 많은 subexpression 의 결과들이 디스크로 쓰여지는 것을 방지하도록 돕습니다. - 그것들이 생성될 때 parent expression 의 결과에 사용하여서 



표현식은 구체화를 통해 평가 될 수 있으며, 시스템은 각 하위 표현식의 결과를 계산하고 디스크에 저장 한 다음이를 사용하여 상위 표현식의 결과를 계산합니다.

해싱과 정렬은 이중입니다. 중복 제거, 프로젝션, 집계, 조인, 외부 조인과 같이 해싱으로 구현할 수있는 모든 작업도 정렬로 구현할 수 있으며 그 반대의 경우도 마찬가지입니다. 즉, 정렬을 통해 구현할 수있는 모든 작업은 해싱으로 구현할 수도 있습니다.





