소위 'Big-data' 분석이라 불리는 최근 데이터 마이닝 어플리케이션은 많은 양의 데이터를 빠르게 관리하도록 요구합니다. 이러한 어플리케이션 중 대다수에 있는 데이터들은 규칙적이고 병렬로 처리할 수 있습니다. 

예를들어

중요도에 따른 웹페이지 랭킹은 수십억 차원의 matrix-vector 곱의 반복과 관련이 있습니다. 이러한 어플리케이션을 PageRank 라고 합니다. 

SNS 에서 친구를 찾는 것은 수백만 노드를 가진 그래프와 관련이 있습니다. 

이러한 것들을 다루기 위한 새로운 소프트웨어 stack 이 연구되고 있습니다. 

이러한 프로그래밍 시스템은 computing clusters 에서 병렬적으로 설계됩니다. Computing clusters 는 기존 프로세서(compute node) 를 switch 나 이더넷 케이블로 연결하여 구성합니다. 

소프트웨어 스택은 새로운 형태의 파일 시스템, 'distributed file system'(DFS) 부터 시작합니다. 이는 기존 운영체제에서의 디스크 블록들 보다 더 큰 단위로 기능합니다. DFS 는 여분의 데이터를 복사하여 데이터가 수천개의 노드로 분배 되었을 때 발생하는 'media failures' 를 예방합니다.

이러한 파일시스템에서는 고수준의 프로그래밍 시스템이 개발되었습니다. MapReduce 프로그래밍 시스템은 이 새로운 소프트웨어 스택의 중심에 있습니다.  MapReduce 의 구현은 대규모 데이터에서의 일반적인 연산의 대부분을 가능하게 하고 이를 computing clusters 에서 수행할 수 있도록 하여 효율적으로 만듭니다. 

맵리듀스 시스템은 빠르게 발전하고 확장되고 있습니다. 오늘날 맵리듀스 프로그램이 더 높은 레벨의 프로그래밍 시스템(SQL과 같은)에서 만들어지는 것이 일반적입니다. 맵리듀스는 유용하면서 간단하고 범용이며 강력한 개념입니다. 여기서는 맵리듀스에 대해 다룹니다. 우선 비동기적인 workflow를 지원하는 시스템에 대해 다루고 재귀 알고리즘으로 구현하는 시스템을 다룹니다.





Distributed File Systems

대부분의 계산은 하나의 프로세서에서 수행됩니다. 이 계산은 메인 메모리와 캐시, 디스크(compute node) 를 갖고 수행됩니다. 이전에는 과학적인 계산과 같이 병렬 처리를 필요로하는 어플리케이션은 특수한 목적의 병렬 컴퓨터에서 수행하였습니다. 이는 많은 프로세서와 특수한 하드웨어로 구성됩니다. 그러나 대규모 웹서비스의 보급으로 수천의 컴퓨트 노드가 독립적으로 운영되는 시설에서 더 많은 계산이 수행되게 되었습니다. 이러한 시설에서 컴퓨트 노드는 상용 하드웨어는 특수목적의 병렬 컴퓨터와 비교하여 가격이 저렴해졌습니다.



이러한 새로운 컴퓨팅 설비는 프로그래밍 시스템의 새로운 시대를 열었습니다. 이 시스템은 병렬화 파워와 동시에 수천의 요소들이 결합한 하드웨어에서 발생할 수 있는 문제들을 해결할 수 있습니다. (fail) 이 세션에서는 이 컴퓨팅 설비의 특징과 이 설비의 이점을 높이는 특수한 파일 시스템의 특징에 대해서 언급합니다. 



211Physical Organization of Compute Nodes

새로운 병렬 컴퓨팅 구조(cluster computing) 은 다음과 같이 구성됩니다. 컴퓨트 노드는 렉(=racks) 에 보관됩니다. 8에서 64개의 노드가 하나의 렉에 보관됩니다. 하나의 렉에 있는 노드들은 하나의 네트워크로 연결됩니다. 일반적으로 연결은 GB의 이더넷(=Ethernet)으로 연결됩니다. 여러개의 노드가 연결된 렉은, 여러개가 있을 수 있고, 그 여러개의 랙들은 다른 레벨의 네트워크나 스위치로 연결됩니다. 렉 간(inter-rack) 대역폭(=bandwidth)은 렉 내부의 이더넷의(intrarack) 대역폭 보다 더 높습니다. 그러나 렉 간의 통신이 필요한 노드들의 쌍의 수가 주어진다면 이 렉 간 대역폭은 더 높아야 합니다. 

그림2.1 은 시스템의 구조를 보여줍니다.

시스템의 컴퓨트 노드나 통신 링크와 같은 컴포넌트들은 더 많아질수록 시스템의 정상작동이 어려워질 수 있습니다. 일반적인 failure 는 단일 노드(해당 노드의 디스크 충돌) 의 손실이나 렉 전체(네트워크 장애)의 손실에서 발생합니다.

일부 중요한 계산은 수천개의 노드에서 몇분에서 몇 시간까지 걸릴 수 있습니다. 만약 하나의 컴포넌트가 실패할 때마다 계산을 중단하고 재시작해야한다면, 그 계산은 영영 못끝낼 수 있습니다. 이러한 문제를 해결하기 위해 2가지 방식이 제시됩니다. 

1. 파일의 여분이 저장되어야 합니다. 파일을 복사하지 않는 경우, 하나의 노드가 실패할 때 그 노드의 파일들은 그 노드가 대체될 때 까지 사용할 수 없습니다. 또, 백업이 안되있는 경우, 디스크 충돌이 발생했을 때, 그 파일은 아예 못쓸수 있습니다. 
2. 계산은 task 로 나눠져야 합니다. 테스크가 실패한다면 그것은 다른 테스트에 영향없이 그 테스크만 재시작하도록 해야합니다. 이 전략은 맵리듀스 프로그래밍 시스템을 따릅니다. 

실제 사용되는 DFS

- Google File System(GFS)
- Hadoop Distributed File System(HDFS)
- Colossus@@



Large-Scale File-System Organization

클러스터 컴퓨팅을 사용하기 위해서는, 파일은 기존 파일 시스템에서 와는 다르게 동작해야합니다. 이러한 새로운 시스템, DFS 는 일반적으로 다음과 같습니다. 

- 파일들이 테라바이트 까지 클 수 있다. 작은 파일인 경우 DFS 를 사용하는 이점이 없다. 
- 파일 갱신(update)은 드물게 일어나야한다. 연산을 위한 데이터로 읽히고(read) 가능하다면, 새로 생기는 데이터는 파일에 추가(append) 되어야 한다. 예를 들어 비행기 예약시스템과 같은 경우 데이터는 매우 크지만 빈번하게 바뀌기 때문에 DFS 에 적합하지않다.

파일은 청크(=chunks)들로 나눠집니다. 청크는 일반적으로 64mb 의 크기를 갖습니다. 청크는 복제되어 다른 컴퓨트 노드들에 저장됩니다. 일반적으로 3개의 사본을 갖습니다. 또한 일반적으로 사본의 청크는 다른 렉에 위치합니다. 그래서 rack failure 에도 파일을 잃지 안도록 합니다. 렉은 랙의 컴퓨트 노드 간 연결이 실패하고 외부와의 통신을 할 수 없기 때문에 fail 이 됩니다. 청크 크기와 사본의 수는 사용자가 결정 할 수 있습니다. 

한 파일의 청크를 찾기 위해서는 마스터 노드(master node, name node) 라고 불리는 작은 파일이 있어야 합니다. 마스터 노드는 자체를 복제된 것입니다. 그리고 파일 청크들의 사본들이 어디 있는 알려주는 디렉토리(directory) 입니다. 디렉토리는 그자체가 복제될 수 있고 DFS를 사용하는 모든 사용자들은 디렉토리 사본들이 어디있는지 알고있습니다. 

